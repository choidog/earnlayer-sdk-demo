# yaml-language-server: $schema=https://api.toolhouse.ai/v1/th-file-schema
  
# Toolhouse Agent Configuration
# The ID of the agent. Do not change this unless you know what you're doing.
id: ec82c6c3-7488-4218-af2a-141cb5428ed4

# The name of the agent. This is used for display purposes.
title: EarnLayer AI Assistant

# The prompt of your agent. You can use variables in the prompt.
system_prompt: |-
  You are a helpful AI assistant that provides contextual responses based on user queries and available resources.
  
  IMPORTANT: When you receive a message that includes "Relevant context and resources:" or "MCP Content:", you MUST:
  1. Acknowledge the MCP context that was provided
  2. Reference any available resources or ads mentioned
  3. Incorporate the context into your response
  4. If no ads/resources are available, explicitly mention this
  5. Provide helpful information based on the context provided
  
  When responding to users:
  1. Always acknowledge the MCP context if provided
  2. If ads or resources are provided, mention them naturally in your response
  3. If no ads are found, explicitly state "No specific ads or resources were found for this query"
  4. Provide helpful, accurate information based on available context
  5. Be conversational and engaging
  6. Always acknowledge the user's question and provide actionable advice

  You will receive enhanced messages that include MCP (Micro-Content Platform) context with relevant ads and resources.
  You MUST use this information to enhance your responses and provide valuable resources to users.

  For technical questions about EarnLayer, Toolhouse, or development:
  - Provide step-by-step instructions
  - Include code examples when relevant
  - Reference official documentation
  - Suggest best practices

# The variables used in the prompt. You can define default values for these variables.
# Ensure that the variable names match those used in the prompt.
vars:
  output: "haiku"

message: "Hello! I'm your AI assistant. I can help you with various topics and provide relevant resources. How can I assist you today?"

# The model you want to use for this agent.
# When using a custom model, ensure to set your API key using the th secrets.
# You can omit this field to use the default model.
# For more information on models, see: https://docs.toolhouse.ai/toolhouse/bring-your-model.
# model: "@groq/llama-3.3-70b-versatile"

# The system prompt. This is used to set the context for the agent. Variables are not allowed in the system prompt.

# The bundle configuration. You can specify a bundle name or a list of MCP servers you want your agent to use.
bundle: "default"

# Sets your agent to be public or private. By default, public agents are visible to all users and can be used by anyone.
# Private agents are only visible to you and can only be used when called with your API Key.
# Toolhouse Pro users can create private agents that are not visible to other users.
public: true

# The end user ID. This is used to give the agent context about the user it is interacting with.
toolhouse_id: "default"

# Schedule configuration. You can specify when the agent should run in cron format.
# schedule: "0 0 * * *" # This would run the agent every day at midnight

# The RAG configuration. You can specify a RAG folder to use.
#rag: "rag_folder"

# A list of MCP servers to use. You can specify a list of MCP servers to use for your agent.
# mcp_servers:
#   - https://mcp.example.com/server1
#   - https://mcp.example.com/server2
